{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prescribed-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bibliographic-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOUD_DIR = '../../data/95cloud'\n",
    "TRAIN_DIR = f'{CLOUD_DIR}/38-Cloud_training'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-spectrum",
   "metadata": {},
   "source": [
    "### Speed test different ways of loading images\n",
    "- Option 1: load all channels independently using PIL, stack the numpy arrays\n",
    "- Option 2: load images from (pre-processed) .png files, which encode the 4 channels as RGBA\n",
    "- Option 3: load images from (pre-processed) .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sporting-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image from 4 channel-wise TIFs and stack them\n",
    "def load_cloud_img_1(patch_name: str):\n",
    "    channel_imgs = []\n",
    "    for channel in ['nir', 'red', 'green', 'blue']:\n",
    "         channel_imgs.append(np.array(Image.open(f'{TRAIN_DIR}/train_{channel}/{channel}_{patch_name}.TIF')))\n",
    "    return np.stack(channel_imgs, axis=2)\n",
    "\n",
    "# read image from RGBA PNG\n",
    "def load_cloud_img_2(patch_name: str, patch_dir: str):\n",
    "    return np.array(Image.open(f'{patch_dir}/{patch_name}.png'))\n",
    "\n",
    "# read image from numpy file\n",
    "def load_cloud_img_3(patch_name: str, patch_dir: str):\n",
    "    return np.load(f'{patch_dir}/{patch_name}.npy')\n",
    "\n",
    "# get the list of training patches and pick 100 random ones to load during the speed test\n",
    "training_patches = np.array(open(f'{TRAIN_DIR}/training_patches_38-Cloud.csv').read().split('\\n')[1:-1])\n",
    "rand_patches = training_patches[np.random.choice(len(training_patches), size=100, replace=False)]\n",
    "\n",
    "# make a temp directory for the preprocessed images\n",
    "temp_preprocess_dir = '/srv/share/sean/datasets/temp_dir_dl_benchmark'\n",
    "if os.path.exists(temp_preprocess_dir):\n",
    "    shutil.rmtree(temp_preprocess_dir, ignore_errors=True)\n",
    "    while os.path.exists(temp_preprocess_dir):\n",
    "        time.sleep(0.1)\n",
    "os.mkdir(temp_preprocess_dir)\n",
    "\n",
    "# pre-process the images\n",
    "for patch_name in rand_patches:\n",
    "    cloud_img = load_cloud_img_1(patch_name)\n",
    "    np.save(open(f'{temp_preprocess_dir}/{patch_name}.npy', 'wb'), cloud_img)\n",
    "    cloud_img_rgba = Image.fromarray(cloud_img, 'RGBA')\n",
    "    cloud_img_rgba.save(f'{temp_preprocess_dir}/{patch_name}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powerful-intro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Load 4 .tif images and stack:\n",
      "254 ms ± 1.24 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "2) Load 1 .png image (rgba):\n",
      "436 ms ± 14 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "\n",
      "3) Load 1 .npy file:\n",
      "78.1 ms ± 223 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Run the test!\n",
    "\n",
    "print('1) Load 4 .tif images and stack:')\n",
    "%timeit for patch_name in rand_patches: load_cloud_img_1(patch_name)\n",
    "\n",
    "print('\\n2) Load 1 .png image (rgba):')\n",
    "%timeit for patch_name in rand_patches: load_cloud_img_2(patch_name, temp_preprocess_dir)\n",
    "\n",
    "print('\\n3) Load 1 .npy file:')\n",
    "%timeit for patch_name in rand_patches: load_cloud_img_3(patch_name, temp_preprocess_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adolescent-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint16 uint8\n"
     ]
    }
   ],
   "source": [
    "# The RGBA option is probably the slowest because PIL internally converts the image to uint8, which is also bad:\n",
    "im1, im2 = load_cloud_img_1(rand_patches[0]), load_cloud_img_2(rand_patches[0], temp_preprocess_dir)\n",
    "print(im1.dtype, im2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-anime",
   "metadata": {},
   "source": [
    "### Pre-processing and saving .npy files is by far the best option in terms of speed!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informal-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the temp directory\n",
    "shutil.rmtree(temp_preprocess_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
